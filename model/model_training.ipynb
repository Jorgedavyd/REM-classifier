{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "Training the actual model that we'll deploy after getting its architecture from the previous step (nn_exploration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data importation\n",
    "\n",
    "dataframe = pd.read_csv('data/data.csv')\n",
    "\n",
    "#Getting the columns\n",
    "columns = dataframe.columns.values\n",
    "\n",
    "#Cleaning the dataframe\n",
    "df = dataframe.drop(columns = columns[0:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2542,  0.0905,  1.1568, -1.1100]), tensor(1.))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split, TensorDataset\n",
    "\n",
    "#Defining input features and target feature\n",
    "input_cols = columns[2:-1]\n",
    "targets = columns[-1]\n",
    "\n",
    "#Getting the tensors\n",
    "inputs, targets = dataframe_to_torch(df,input_cols, targets)\n",
    "\n",
    "#Creating the dataset\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "\n",
    "dataset[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Test:15% training: 85%\n",
    "\n",
    "test_size = round(0.15*len(dataset))\n",
    "\n",
    "\n",
    "train_ds, test_ds = random_split(dataset , [len(dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 128  #Change based on GPU capacity\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size*2, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and ouput values of the hidden layers (input the values from the cross-validation step)\n",
    "architecture = (28,60,30)\n",
    "\n",
    "# Model definition \n",
    "model = DeepNeuralNetwork(4, *architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m#Training\u001b[39;00m\n\u001b[1;32m      9\u001b[0m history \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 11\u001b[0m history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m fit(epochs, max_lr, model, train_loader, test_loader, weight_decay, grad_clip, opt_func)\n",
      "File \u001b[0;32m~/Desktop/REM-classifier/model/utils.py:159\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, max_lr, model, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[1;32m    156\u001b[0m lrs \u001b[39m=\u001b[39m [] \u001b[39m# Seguimiento\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m    158\u001b[0m     \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtraining_step(batch)\n\u001b[1;32m    160\u001b[0m     \u001b[39m#Seguimiento\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m~/Desktop/REM-classifier/model/utils.py:77\u001b[0m, in \u001b[0;36mRemClassificationBase.training_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     75\u001b[0m inputs, targets \u001b[39m=\u001b[39m batch\n\u001b[1;32m     76\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(inputs)                  \u001b[39m# Generar predicciones\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m loss \u001b[39m=\u001b[39m binary_cross_entropy(out, targets) \u001b[39m# Calcular el costo\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:3089\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3087\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3088\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m-> 3089\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3092\u001b[0m     )\n\u001b[1;32m   3094\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3095\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "epochs = 15\n",
    "max_lr = 0.0001\n",
    "grad_clip = 0.007\n",
    "weight_decay = 1e-5\n",
    "opt_func = torch.optim.Adam\n",
    "\n",
    "#Training\n",
    "history = []\n",
    "\n",
    "history += fit(epochs, max_lr, model, train_loader, test_loader, weight_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This step creates a readable model for a variety of programing languages.\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save('model.pt') # Save\n",
    "#ONNX export\n",
    "dummy_input = torch.randn() #cambiar luego\n",
    "torch.onnx.export(model, dummy_input, 'model.onnx', verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
